#!/usr/bin/env python3
"""
WebVuln AI Analyzer - VersÃ£o Elite 2026
Analisador DinÃ¢mico de Vulnerabilidades Web com HTTPX e Playwright
"""

import asyncio
import httpx
import re
import json
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from datetime import datetime
from playwright.async_api import async_playwright
import warnings

warnings.filterwarnings('ignore')

class WebVulnAnalyzer:
    """Analisador de elite com suporte a renderizaÃ§Ã£o dinÃ¢mica e requisiÃ§Ãµes assÃ­ncronas"""
    
    def __init__(self, target_url, timeout=30):
        self.target_url = target_url
        self.timeout = timeout
        self.vulnerabilities = []
        self.api_endpoints = set()
        self.technologies = {}
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }

    async def full_scan(self):
        """Executa scan completo usando motor assÃ­ncrono e dinÃ¢mico"""
        print(f"\nðŸš€ WebVuln AI Analyzer [ELITE] - Scan Completo")
        print(f"ðŸŽ¯ Alvo: {self.target_url}")
        print("="*80)
        
        results = {
            "target": self.target_url,
            "timestamp": datetime.now().isoformat(),
            "vulnerabilities": [],
            "security_headers": {},
            "cookies": {},
            "dynamic_analysis": {},
            "api_endpoints": [],
            "risk_score": 0
        }

        async with httpx.AsyncClient(headers=self.headers, timeout=self.timeout, verify=False, follow_redirects=True) as client:
            # 1. AnÃ¡lise de Headers e Cookies (EstÃ¡tico + RÃ¡pido)
            print("[1/5] ðŸ›¡ï¸  Analisando headers e cookies...")
            response = await client.get(self.target_url)
            results["security_headers"] = self._analyze_headers(response.headers)
            results["cookies"] = self._analyze_cookies(response.cookies)

            # 2. AnÃ¡lise DinÃ¢mica com Playwright (O "Pulo do Gato")
            print("[2/5] ðŸŽ­ Iniciando anÃ¡lise dinÃ¢mica (Playwright)...")
            results["dynamic_analysis"] = await self._analyze_dynamically()

            # 3. Descoberta de Endpoints (HÃ­brido)
            print("[3/5] ðŸ”— Descobrindo endpoints de API...")
            results["api_endpoints"] = list(self.api_endpoints)

            # 4. CÃ¡lculo de Risco
            print("[4/5] ðŸ“Š Calculando Risk Score...")
            results["vulnerabilities"] = self.vulnerabilities
            results["risk_score"] = self._calculate_risk_score()

            # 5. FinalizaÃ§Ã£o
            print("[5/5] âœ… Scan concluÃ­do!")
            
        return results

    def _analyze_headers(self, headers):
        sec_headers = ["X-Frame-Options", "Content-Security-Policy", "Strict-Transport-Security", "X-Content-Type-Options"]
        analysis = {}
        for h in sec_headers:
            val = headers.get(h)
            analysis[h] = val if val else "MISSING"
            if not val:
                self.vulnerabilities.append({
                    "type": "Missing Security Header",
                    "severity": "MEDIUM",
                    "description": f"Header {h} nÃ£o configurado."
                })
        return analysis

    def _analyze_cookies(self, cookies):
        analysis = {}
        for name, value in cookies.items():
            # Nota: httpx.Cookies nÃ£o tem todos os atributos como requests.CookieJar diretamente acessÃ­veis da mesma forma
            analysis[name] = {"value": value[:10] + "..."}
        return analysis

    async def _analyze_dynamically(self):
        """Usa Playwright para ver o que o BeautifulSoup nÃ£o vÃª"""
        dynamic_data = {"requests": [], "console_logs": [], "errors": []}
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(user_agent=self.headers['User-Agent'])
            page = await context.new_page()

            # Monitorar requisiÃ§Ãµes de rede (AJAX/Fetch)
            page.on("request", lambda request: self.api_endpoints.add(request.url) if "/api/" in request.url else None)
            page.on("console", lambda msg: dynamic_data["console_logs"].append(msg.text))
            page.on("pageerror", lambda exc: dynamic_data["errors"].append(str(exc)))

            try:
                await page.goto(self.target_url, wait_until="networkidle", timeout=self.timeout * 1000)
                
                # Procurar por dados sensÃ­veis no DOM renderizado
                content = await page.content()
                if "apiKey" in content or "access_token" in content:
                    self.vulnerabilities.append({
                        "type": "Sensitive Data in DOM",
                        "severity": "HIGH",
                        "description": "PossÃ­veis chaves de API ou tokens expostos no DOM renderizado."
                    })
                
                dynamic_data["title"] = await page.title()
                dynamic_data["screenshot_taken"] = True # Em um sistema real, salvarÃ­amos o screenshot
                
            except Exception as e:
                dynamic_data["error"] = str(e)
            finally:
                await browser.close()
        
        return dynamic_data

    def _calculate_risk_score(self):
        score = 0
        for v in self.vulnerabilities:
            if v["severity"] == "CRITICAL": score += 25
            elif v["severity"] == "HIGH": score += 15
            elif v["severity"] == "MEDIUM": score += 5
        return min(score, 100)

# Wrapper para execuÃ§Ã£o sÃ­ncrona (compatibilidade com backend atual)
def run_scan(target_url):
    analyzer = WebVulnAnalyzer(target_url)
    return asyncio.run(analyzer.full_scan())

if __name__ == "__main__":
    import sys
    target = sys.argv[1] if len(sys.argv) > 1 else "https://99jogo66.com/?id=211995351"
    report = run_scan(target)
    print(json.dumps(report, indent=2))
